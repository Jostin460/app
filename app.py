# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16rgEIYQ5AbHMabFO9vNCosnF4q5V3B5W
"""

import streamlit as st
import pandas as pd
from openai import OpenAI
import os

# ----------------------------
# CONFIGURACI√ìN DE LA APP
# ----------------------------
st.title("üß† Mental Health Data Analysis Assistant")
st.write("Haz preguntas sobre el dataset de trastornos mentales o analiza tendencias globales.")

# ----------------------------
# ENTRADAS DEL USUARIO
# ----------------------------
# Recuadro 1: Texto de la pregunta
question = st.text_area("‚úçÔ∏è Escribe tu pregunta sobre el dataset:",
                        placeholder="Ejemplo: ¬øCu√°l es el pa√≠s con mayor porcentaje de depresi√≥n en 2015?")

# Recuadro 2: Clave de API
api_key = st.text_input("üîë Ingresa tu clave de API de OpenAI:", type="password")

# ----------------------------
# CARGA DEL DATASET
# ----------------------------
uploaded_file = st.file_uploader("üìÇ Sube tu archivo CSV (dataset de salud mental)", type="csv")

if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)
        st.success("‚úÖ Archivo cargado correctamente.")
        st.dataframe(df.head())
    except Exception as e:
        st.error(f"‚ùå Error al cargar el archivo: {e}")
        st.stop()
else:
    st.info("Por favor, sube el archivo CSV antes de continuar.")
    st.stop()

# ----------------------------
# PROCESAR PREGUNTA CON OPENAI
# ----------------------------
if st.button("üîç Analizar pregunta"):
    if not api_key:
        st.error("Por favor, ingresa tu clave de API para continuar.")
        st.stop()

    # Guardar la API Key temporalmente
    os.environ["OPENAI_API_KEY"] = api_key
    client = OpenAI(api_key=api_key)

    # Convertir dataset a texto (resumen, no todo)
    df_string = df.head(10).to_string()  # Solo las primeras filas para no saturar el prompt

    # Sistema con instrucciones para controlar el tipo de respuesta
    system_prompt = (
        "Eres un analista de datos experto en salud mental. "
        "Tienes acceso a un dataset con las siguientes columnas: "
        "'Entity' (pa√≠s o regi√≥n), 'Code' (c√≥digo del pa√≠s), 'Year' (a√±o del registro), "
        "'Schizophrenia (%)', 'Bipolar disorder (%)', 'Eating disorders (%)', "
        "'Anxiety disorders (%)', 'Drug use disorders (%)', 'Depression (%)', "
        "y 'Alcohol use disorders (%)'. "
        "El dataset muestra la prevalencia porcentual de diferentes trastornos mentales en distintos pa√≠ses y a√±os. "
        "Si la pregunta del usuario NO est√° relacionada con este dataset o con an√°lisis de salud mental, "
        "responde amablemente diciendo que no puedes responder porque la pregunta est√° fuera del alcance del conjunto de datos."
    )

    # Enviar la solicitud al modelo
    try:
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Aqu√≠ est√°n los primeros datos:\n{df_string}"},
                {"role": "user", "content": question}
            ],
            temperature=0.7
        )

        # Mostrar respuesta
        answer = response.choices[0].message.content
        st.subheader("üß© Respuesta del modelo:")
        st.write(answer)

    except Exception as e:
        st.error(f"‚ö†Ô∏è Error al consultar el modelo: {e}")
